{
 "cells": [
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Optimizing Evacuation Routes using Real-Time Traffic Information"
   ]
  },
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Michael Daugherty | US-DSI-10 | 02.21.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting tweets from police departments of 30 of the most populous cities in Texas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got, import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of police department Twitter feeds to pull from\n",
    "twitter_feeds = [\n",
    "    \"houstonpolice\",\n",
    "    \"SATXPolice\",\n",
    "    \"DallasPD\",\n",
    "    \"Austin_Police\",\n",
    "    \"fortworthpd\",\n",
    "    \"EPPOLICE\",\n",
    "    \"ArlingtonPD\",\n",
    "    \"CorpusChristiPD\",\n",
    "    \"PlanoPoliceDept\",\n",
    "    \"mylaredopd\",\n",
    "    \"LubbockPolice\",\n",
    "    \"GarlandPD\",\n",
    "    \"irvingpd\",\n",
    "    \"amarillopd\",\n",
    "    \"GrandPrairiePD\",\n",
    "    \"McKinneyPolice\",\n",
    "    \"friscopd\",\n",
    "    \"PasPoliceTx\",\n",
    "    \"KilleenPD\",\n",
    "    \"MidlandTxPD\",\n",
    "    \"DentonPolice\",\n",
    "    \"WacoPolice\",\n",
    "    \"carrolltontxpd\",\n",
    "    \"roundrockpolice\",\n",
    "    \"abilenepd\",\n",
    "    \"PearlandPD\",\n",
    "    \"RichardsonTX_PD\",\n",
    "    \"odessapolice\",\n",
    "    \"Sugar_Land_TX\",\n",
    "    \"beaumont_police\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feed in twitter_feeds:    # A\n",
    "    start_date = \"2016-01-01\" # B\n",
    "    end_date = \"2020-02-10\"   # B\n",
    "    max_tweets = 18_000       # C\n",
    "    \n",
    "    tweetCriteria = (got.\n",
    "    manager.\n",
    "    TweetCriteria().\n",
    "    setUsername(feed).        # specify which Twitter feed to pull from (A)\n",
    "    setSince(start_date).\n",
    "    setUntil(end_date).       # specify date range to pull from (B)\n",
    "    setMaxTweets(max_tweets)) # limit tweets to 18k to avoid getting locked out (C)\n",
    "    \n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria) # pull the tweets\n",
    "    user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets] # list of the tweets + info\n",
    "    tweets_df = pd.DataFrame(user_tweets) # make a DataFrame of the tweets and their associated information\n",
    "    tweets_df.to_csv(f\"./data/test_data/test_data_by_user/{feed}_tweets.csv\") # export the DataFrame to a CSV in the project data directory\n",
    "    time.sleep(15*60) # wait 15 minutes before starting the next batch to avoid getting locked out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a CSV of tweets from police departments during hurricane Harvey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"./data/test_data/test_data_by_user/\") # create a list of the CSV files created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvey_dfs = list() # create an empty list to store DataFrames of tweets from the relevant time period\n",
    "\n",
    "for file in files:\n",
    "    tweets = pd.read_csv(f\"./data/project_data/{file}\") # read the CSV back in as a DataFrame\n",
    "    fewer_tweets = tweets[(tweets[\"0\"] >= \"2017-08-25\") & (tweets[\"0\"] <= \"2017-09-03\")] # select tweets from 8/25-9/2/2017\n",
    "    harvey_dfs.append(fewer_tweets) # put those tweets in the list created above\n",
    "\n",
    "harvey_tweets = pd.concat(harvey_tweets) # stack all of the DataFrames of tweets from 8/25-9/2 into a single DataFrame\n",
    "harvey_tweets.to_csv(\"./data/test_data/PD_HH_tweets.csv\") # export to a CSV in the project data directory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
