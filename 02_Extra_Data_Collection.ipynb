{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Optimizing Evacuation Routes using Real-Time Traffic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelly Slatery | US-DSI-10 | 02.21.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits (using GetOldTweets3 package): Martin Beck, 01.12.2020\n",
    "# https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "\n",
    "# Set up variables for first Twitter pull\n",
    "username = 'TxDOT'\n",
    "since_date = '2016-01-01'\n",
    "until_date = '2020-02-10'\n",
    "max_tweets = 10000\n",
    "\n",
    "# Create first query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "# Greate first list of all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# Create filtered list of tweet data\n",
    "user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "# Transform list into the base tweet collection dataframe\n",
    "all_tweets = pd.DataFrame(user_tweets)\n",
    "\n",
    "# Export to dataframe\n",
    "all_tweets.to_csv(f'./data/train_data/train_data_by_user/TxDOT_tweets', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-07 22:20:09+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>When you drink and drive in Texas, our officer...</td>\n",
       "      <td>#PlanWhileYouCan #EndTheStreakTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-07 18:05:12+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Want to help traffic instead of sitting in it?...</td>\n",
       "      <td>#TxDOTCareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-07 01:10:04+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Are you skilled in automotive work? We'd love ...</td>\n",
       "      <td>#TxDOTCareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-07 00:15:25+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>From a shout to a whisper, we can’t emphasize ...</td>\n",
       "      <td>#EndTheStreakTX #ClickItOrTicket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-06 22:14:22+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>We love seeing all the nice things y’all have ...</td>\n",
       "      <td>#txwx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0      1  \\\n",
       "0 2020-02-07 22:20:09+00:00  TxDOT   \n",
       "1 2020-02-07 18:05:12+00:00  TxDOT   \n",
       "2 2020-02-07 01:10:04+00:00  TxDOT   \n",
       "3 2020-02-07 00:15:25+00:00  TxDOT   \n",
       "4 2020-02-06 22:14:22+00:00  TxDOT   \n",
       "\n",
       "                                                   2  \\\n",
       "0  When you drink and drive in Texas, our officer...   \n",
       "1  Want to help traffic instead of sitting in it?...   \n",
       "2  Are you skilled in automotive work? We'd love ...   \n",
       "3  From a shout to a whisper, we can’t emphasize ...   \n",
       "4  We love seeing all the nice things y’all have ...   \n",
       "\n",
       "                                  3  \n",
       "0  #PlanWhileYouCan #EndTheStreakTX  \n",
       "1                     #TxDOTCareers  \n",
       "2                     #TxDOTCareers  \n",
       "3  #EndTheStreakTX #ClickItOrTicket  \n",
       "4                             #txwx  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 5 tweets from 'TxDOT'\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>2016-01-04 00:08:24+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>I-35 Alert: 10 vehicle crash closed down all m...</td>\n",
       "      <td>#my35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>2016-01-01 16:20:21+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Make a #resolution to start 2016 right. #PlanW...</td>\n",
       "      <td>#resolution #PlanWhileYouCan #FindASoberRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>2016-01-01 13:30:35+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>TxDOT offices will be closed today, Jan. 1 in ...</td>\n",
       "      <td>#NewYear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>2016-01-01 05:55:08+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>#HappyNewYear from #TxDOT! We hope everyone ha...</td>\n",
       "      <td>#HappyNewYear #TxDOT #NYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>2016-01-01 00:10:13+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Don't start the #NewYear w/ a DWI. #PlanWhileY...</td>\n",
       "      <td>#NewYear #PlanWhileYouCan #FindASoberRide #Hap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0      1  \\\n",
       "4080 2016-01-04 00:08:24+00:00  TxDOT   \n",
       "4081 2016-01-01 16:20:21+00:00  TxDOT   \n",
       "4082 2016-01-01 13:30:35+00:00  TxDOT   \n",
       "4083 2016-01-01 05:55:08+00:00  TxDOT   \n",
       "4084 2016-01-01 00:10:13+00:00  TxDOT   \n",
       "\n",
       "                                                      2  \\\n",
       "4080  I-35 Alert: 10 vehicle crash closed down all m...   \n",
       "4081  Make a #resolution to start 2016 right. #PlanW...   \n",
       "4082  TxDOT offices will be closed today, Jan. 1 in ...   \n",
       "4083  #HappyNewYear from #TxDOT! We hope everyone ha...   \n",
       "4084  Don't start the #NewYear w/ a DWI. #PlanWhileY...   \n",
       "\n",
       "                                                      3  \n",
       "4080                                              #my35  \n",
       "4081       #resolution #PlanWhileYouCan #FindASoberRide  \n",
       "4082                                           #NewYear  \n",
       "4083                          #HappyNewYear #TxDOT #NYE  \n",
       "4084  #NewYear #PlanWhileYouCan #FindASoberRide #Hap...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at last 5 tweets from 'TxDOT'\n",
    "all_tweets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of Twitter usernames to scrape, exclusing first Twitter user ('TxDOT')\n",
    "# From: https://www.txdot.gov/driver/weather/txdot-twitter-feeds.html\n",
    "twitter_users = ['TxDOTAbilene', 'TxDOTAmarillo', 'TxDOTAtlanta', 'TxDOTAustin', \n",
    "                 'TxDOTBeaumont', 'TxDOTBWD', 'TxDOTBryan', 'TxDOTChildress', 'TxDOT_CRP', \n",
    "                 'TxDOTDallas', 'TxDOTELP', 'TxDOTFortWorth', 'GalvestonFerry', 'TxDOTHouston', \n",
    "                 'HoustonTranstar', 'I35Travel', 'TxDOTLaredo', 'TxDOTLubbock', 'TxDOTLufkin', \n",
    "                 'TxDOTOdessa', 'TxDOTParis', 'TxDOTPharr', 'PortA_Ferry', 'TxDOTSanAngelo', \n",
    "                 'TxDOTSanAntonio', 'TexasHighways', 'TxDOTTyler', 'TxDOTWacoPIO', 'TXDOTWF', \n",
    "                 'TxDOTYoakum', 'ImproveMopac', 'ManorExpressway', 'DFWConnector', 'DriveMidtown', \n",
    "                 'Drive360South', 'LBJexpress', 'NTExpress', 'my290Houston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many Twitters are we scraping?\n",
    "len(twitter_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull remaining users' tweets from the same time period\n",
    "def update_tweets(base_df, user):\n",
    "    \n",
    "    # Set up variables for first Twitter pull\n",
    "    username = user\n",
    "    since_date = '2016-01-01'\n",
    "    until_date = '2020-02-10'\n",
    "    max_tweets = 10000\n",
    "\n",
    "    # Create first query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "    # Greate first list of all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Create filtered list of tweet data\n",
    "    user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "    # Transform list into the base tweet collection dataframe\n",
    "    tweets_df = pd.DataFrame(user_tweets)\n",
    "    \n",
    "    # Concatenate new tweets with old tweets\n",
    "    updated = pd.concat([base_df, tweets_df], axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    # Export the new dataframe individually\n",
    "    tweets_df.to_csv(f'./data/train_data/train_data_by_user/{user}_tweets', index=False)\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Done scraping. We added {len(user_tweets)} new tweets. Current df shape: {updated.shape}')\n",
    "    \n",
    "    # Return updated dataframe of all tweets\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter #1 now scraping...\n",
      "Done scraping. We added 1196 new tweets. Current df shape: (5281, 4)\n",
      "\n",
      "Time elapsed: 30.133867025375366\n",
      "Twitter #2 now scraping...\n",
      "Done scraping. We added 1757 new tweets. Current df shape: (7038, 4)\n",
      "\n",
      "Time elapsed: 46.58091187477112\n",
      "Twitter #3 now scraping...\n",
      "Done scraping. We added 356 new tweets. Current df shape: (7394, 4)\n",
      "\n",
      "Time elapsed: 10.286750793457031\n",
      "Twitter #4 now scraping...\n",
      "Done scraping. We added 5420 new tweets. Current df shape: (12814, 4)\n",
      "\n",
      "Time elapsed: 144.51120901107788\n",
      "Twitter #5 now scraping...\n",
      "Done scraping. We added 2231 new tweets. Current df shape: (15045, 4)\n",
      "\n",
      "Time elapsed: 52.47301006317139\n",
      "Twitter #6 now scraping...\n",
      "Done scraping. We added 586 new tweets. Current df shape: (15631, 4)\n",
      "\n",
      "Time elapsed: 16.99058508872986\n",
      "Twitter #7 now scraping...\n",
      "Done scraping. We added 762 new tweets. Current df shape: (16393, 4)\n",
      "\n",
      "Time elapsed: 19.221446752548218\n",
      "Twitter #8 now scraping...\n",
      "Done scraping. We added 1761 new tweets. Current df shape: (18154, 4)\n",
      "\n",
      "Time elapsed: 42.15876889228821\n",
      "Twitter #9 now scraping...\n",
      "Done scraping. We added 790 new tweets. Current df shape: (18944, 4)\n",
      "\n",
      "Time elapsed: 20.954066038131714\n",
      "Twitter #10 now scraping...\n",
      "Done scraping. We added 1169 new tweets. Current df shape: (20113, 4)\n",
      "\n",
      "Time elapsed: 28.77706789970398\n",
      "Twitter #11 now scraping...\n",
      "Done scraping. We added 4411 new tweets. Current df shape: (24524, 4)\n",
      "\n",
      "Time elapsed: 116.68503975868225\n",
      "Twitter #12 now scraping...\n",
      "Done scraping. We added 1655 new tweets. Current df shape: (26179, 4)\n",
      "\n",
      "Time elapsed: 40.9729118347168\n",
      "Twitter #13 now scraping...\n",
      "Done scraping. We added 11860 new tweets. Current df shape: (38039, 4)\n",
      "\n",
      "Time elapsed: 264.7479999065399\n",
      "Twitter #14 now scraping...\n",
      "Done scraping. We added 7040 new tweets. Current df shape: (45079, 4)\n",
      "\n",
      "Time elapsed: 171.63731694221497\n",
      "Twitter #15 now scraping...\n",
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=%20from%3Ahoustontranstar%20since%3A2016-01-01%20until%3A2020-02-10&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/anaconda3/envs/dsi/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Get tweets from next 14 of the total 39 twitters users and add to the all_tweets dataframe\n",
    "\n",
    "# Set up count\n",
    "i = 0\n",
    "\n",
    "# Loop through all twitter users to scrape and add to the all_tweets dataframe, according to Twitter API limits\n",
    "for user in twitter_users:\n",
    "\n",
    "    # Count twitters as they are scraped and get the initial time\n",
    "    i += 1\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Twitter #{i} now scraping...')\n",
    "    \n",
    "    # Get the tweets and update the dataframe\n",
    "    all_tweets = update_tweets(all_tweets, user)\n",
    "    \n",
    "    # Wait the the remainder of 15 minutes\n",
    "    print(f'Time elapsed: {time.time() - t0}')\n",
    "    time.sleep((15*60) - (time.time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export first round of data as one dataframe\n",
    "all_tweets.to_csv('./data/train_data/DOT1_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HoustonTranstar', 'I35Travel', 'TxDOTLaredo']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update list of Twitters still needed to be scraped\n",
    "remaining_twitter_users = twitter_users[14:]\n",
    "remaining_twitter_users[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Set up variables for first Twitter pull of second attempt\n",
    "username = 'HoustonTranstar'\n",
    "since_date = '2016-01-01'\n",
    "until_date = '2020-02-10'\n",
    "max_tweets = 10000\n",
    "\n",
    "# Create first query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "# Greate first list of all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# Create filtered list of tweet data\n",
    "user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "# Transform list into the base tweet collection dataframe\n",
    "all_tweets2 = pd.DataFrame(user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-07 22:17:07+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>http://traffic.houstontranstar.org/layers/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-07 17:48:31+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>REMINDER: All mainlanes of I-610 West Loop (NB...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-07 15:53:52+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>http://traffic.houstontranstar.org/layers/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-07 15:38:03+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>http://traffic.houstontranstar.org/layers/</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-06 16:04:45+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>More information related to this closure can b...</td>\n",
       "      <td>#HoustonTranStar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0                1  \\\n",
       "0 2020-02-07 22:17:07+00:00  houstontranstar   \n",
       "1 2020-02-07 17:48:31+00:00  houstontranstar   \n",
       "2 2020-02-07 15:53:52+00:00  houstontranstar   \n",
       "3 2020-02-07 15:38:03+00:00  houstontranstar   \n",
       "4 2020-02-06 16:04:45+00:00  houstontranstar   \n",
       "\n",
       "                                                   2                 3  \n",
       "0         http://traffic.houstontranstar.org/layers/                    \n",
       "1  REMINDER: All mainlanes of I-610 West Loop (NB...                    \n",
       "2         http://traffic.houstontranstar.org/layers/                    \n",
       "3         http://traffic.houstontranstar.org/layers/                    \n",
       "4  More information related to this closure can b...  #HoustonTranStar  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 5 tweets from 'HoustonTranstar'\n",
    "all_tweets2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2018-07-30 15:36:05+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>IH-10 KATY Eastbound At PARK TEN - Heavy Truck...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2018-07-30 15:21:05+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>IH-69 Eastex Freeway Southbound At FRANKLIN ST...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2018-07-30 15:09:05+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>IH-69 Eastex Freeway Southbound At FRANKLIN ST...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2018-07-30 15:00:05+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>NORTH SAM HOUSTON TOLLWAY Eastbound At NORTH S...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2018-07-30 14:54:05+00:00</td>\n",
       "      <td>houstontranstar</td>\n",
       "      <td>US-290 NORTHWEST Westbound After TELGE RD - St...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                1  \\\n",
       "9995 2018-07-30 15:36:05+00:00  houstontranstar   \n",
       "9996 2018-07-30 15:21:05+00:00  houstontranstar   \n",
       "9997 2018-07-30 15:09:05+00:00  houstontranstar   \n",
       "9998 2018-07-30 15:00:05+00:00  houstontranstar   \n",
       "9999 2018-07-30 14:54:05+00:00  houstontranstar   \n",
       "\n",
       "                                                      2 3  \n",
       "9995  IH-10 KATY Eastbound At PARK TEN - Heavy Truck...    \n",
       "9996  IH-69 Eastex Freeway Southbound At FRANKLIN ST...    \n",
       "9997  IH-69 Eastex Freeway Southbound At FRANKLIN ST...    \n",
       "9998  NORTH SAM HOUSTON TOLLWAY Eastbound At NORTH S...    \n",
       "9999  US-290 NORTHWEST Westbound After TELGE RD - St...    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at last 5 tweets from 'HoustonTranstar'\n",
    "all_tweets2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter #1 now scraping...\n",
      "Done scraping. We added 10000 new tweets. Current df shape: (20000, 4)\n",
      "Done. Time elapsed: 247.74167275428772\n",
      "\n",
      "Twitter #2 now scraping...\n",
      "Done scraping. We added 2740 new tweets. Current df shape: (22740, 4)\n",
      "Done. Time elapsed: 76.26691198348999\n",
      "\n",
      "Twitter #3 now scraping...\n",
      "Done scraping. We added 1305 new tweets. Current df shape: (24045, 4)\n",
      "Done. Time elapsed: 38.40343976020813\n",
      "\n",
      "Twitter #4 now scraping...\n",
      "Done scraping. We added 1996 new tweets. Current df shape: (26041, 4)\n",
      "Done. Time elapsed: 51.653087854385376\n",
      "\n",
      "Twitter #5 now scraping...\n",
      "Done scraping. We added 1904 new tweets. Current df shape: (27945, 4)\n",
      "Done. Time elapsed: 50.5319139957428\n",
      "\n",
      "Twitter #6 now scraping...\n",
      "Done scraping. We added 739 new tweets. Current df shape: (28684, 4)\n",
      "Done. Time elapsed: 23.571969032287598\n",
      "\n",
      "Twitter #7 now scraping...\n",
      "Done scraping. We added 1697 new tweets. Current df shape: (30381, 4)\n",
      "Done. Time elapsed: 48.53655004501343\n",
      "\n",
      "Twitter #8 now scraping...\n",
      "Done scraping. We added 4487 new tweets. Current df shape: (34868, 4)\n",
      "Done. Time elapsed: 113.40442776679993\n",
      "\n",
      "Twitter #9 now scraping...\n",
      "Done scraping. We added 890 new tweets. Current df shape: (35758, 4)\n",
      "Done. Time elapsed: 25.730948209762573\n",
      "\n",
      "Twitter #10 now scraping...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5009cad2045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Get the tweets and update the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mall_tweets2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tweets2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Wait the the remainder of 15 minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-8f0ff83e290b>\u001b[0m in \u001b[0;36mupdate_tweets\u001b[0;34m(base_df, user)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Greate first list of all tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTweetManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetCriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Create filtered list of tweet data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/site-packages/GetOldTweets3/manager/TweetManager.py\u001b[0m in \u001b[0;36mgetTweets\u001b[0;34m(tweetCriteria, receiveBuffer, bufferLength, proxy, debug)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mactive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mactive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mjson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTweetManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetJsonResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweetCriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefreshCursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcookieJar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'items_html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/site-packages/GetOldTweets3/manager/TweetManager.py\u001b[0m in \u001b[0;36mgetJsonResponse\u001b[0;34m(tweetCriteria, refreshCursor, cookieJar, proxy, useragent, debug)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0mjsonResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"An error occured during an HTTP request:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dsi/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue scraping: Get tweets from next 9 of remaining 23 twitters users and add to the all_tweets dataframe\n",
    "\n",
    "# Set up count\n",
    "i = 0\n",
    "\n",
    "# Loop through all remaining twitter users to scrape and add to the all_tweets dataframe, \n",
    "# according to Twitter API limits\n",
    "for user in remaining_twitter_users[1:]:\n",
    "\n",
    "    # Count twitters as they are scraped and get the initial time\n",
    "    i += 1\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Twitter #{i} now scraping...')\n",
    "    \n",
    "    # Get the tweets and update the dataframe\n",
    "    all_tweets2 = update_tweets(all_tweets2, user)\n",
    "    \n",
    "    # Wait the the remainder of 15 minutes\n",
    "    print(f'Done. Time elapsed: {time.time() - t0}')\n",
    "    print()\n",
    "    time.sleep(15*60)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export second round of data as one dataframe\n",
    "all_tweets2.to_csv('./data/train_data/DOT2_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import first round of data\n",
    "tweets1 = pd.read_csv('./data/DOT1_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import second round of data\n",
    "tweets2 = pd.read_csv('./data/DOT2_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80837, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all tweets from first 25 of 38 twitters\n",
    "all_tweets_final = pd.concat([tweets1, tweets2], axis=0, ignore_index=True, sort=True)\n",
    "all_tweets_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export full dataset of all tweets from first 25 of 38 twitters\n",
    "all_tweets_final.to_csv('./data/train_data/DOT_full_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
