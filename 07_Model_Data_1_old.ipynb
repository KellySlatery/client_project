{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Optimizing Evacuation Routes using Real-Time Traffic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kelly Slatery | US-DSI-10 | 02.21.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, \\\n",
    "                             GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# Revise this imports list\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165204, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train_data/final_train_data.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates&amp;time</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-06 22:03:12+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>DallasPD and dfrincidents are currently on loc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-30 21:16:20+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Monday Sept   on LaborDay Jack Evans Police Hd...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-14 22:31:39+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>PIODPD is at the scene of a possible barricade...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-07-13 22:04:27+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>PIODPD is on scene of an Officer Involved Shoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-13 01:38:19+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Major police incident in downtown Dallas Griff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dates&time      user  \\\n",
       "0  2020-02-06 22:03:12+00:00  DallasPD   \n",
       "1  2019-08-30 21:16:20+00:00  DallasPD   \n",
       "2  2019-08-14 22:31:39+00:00  DallasPD   \n",
       "3  2019-07-13 22:04:27+00:00  DallasPD   \n",
       "4  2019-07-13 01:38:19+00:00  DallasPD   \n",
       "\n",
       "                                               tweet  class  \n",
       "0  DallasPD and dfrincidents are currently on loc...      1  \n",
       "1  Monday Sept   on LaborDay Jack Evans Police Hd...      1  \n",
       "2  PIODPD is at the scene of a possible barricade...      1  \n",
       "3  PIODPD is on scene of an Officer Involved Shoo...      1  \n",
       "4  Major police incident in downtown Dallas Griff...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dates&time    0\n",
       "user          0\n",
       "tweet         0\n",
       "class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.948833\n",
       "1    0.051167\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the y value distribution\n",
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Accuracy: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df['tweet']\n",
    "y = df['class']\n",
    "\n",
    "# Train tes split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.25, \n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: CountVecotorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "lr_cv_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('lr', LogisticRegression(solver='liblinear')) \n",
    "])\n",
    "\n",
    "# Set up pipeline parameters\n",
    "lr_cv_params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)], \n",
    "    'cvec__max_features': [100, 500], \n",
    "    'cvec__max_df': [1.0, .95], \n",
    "    'cvec__min_df': [1, .05], \n",
    "    'lr__C': [1, 1e9], \n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__max_iter': [100, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 45.8min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 63.8min\n",
      "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed: 75.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Set up gridsearch\n",
    "lr_cv_gs = GridSearchCV(lr_cv_pipe, lr_cv_params, n_jobs=4, cv=5, verbose=1)\n",
    "\n",
    "# Fit the gridsearch to the training data\n",
    "lr_cv_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971509971509972"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was our highest cross-val accuracy score across model hyperparameter combinations?\n",
    "lr_cv_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=500, min_df=1, ngram_range=(1, 2),\n",
       "                                 preprocessor=None, stop_words=None,\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l1', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What model hyperparameters yielded the highest accuracy score?\n",
    "lr_cv_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 1.0,\n",
       " 'cvec__max_features': 500,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None,\n",
       " 'lr__C': 1,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__penalty': 'l1'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the parameters?\n",
    "lr_cv_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972639887654052"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this model perform on the test set?\n",
    "lr_cv_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs with high accuracy on both the train and test datasets. It is neither overfit nor underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: TfidfVecotorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "lr_tv_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('lr', LogisticRegression(solver='liblinear')) \n",
    "])\n",
    "\n",
    "# Set up pipeline parameters\n",
    "lr_tv_params = {\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)], \n",
    "    'tvec__max_features': [100, 500], \n",
    "    'tvec__max_df': [1.0, .95], \n",
    "    'tvec__min_df': [1, .05], \n",
    "    'lr__C': [1, 1e9], \n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "    'lr__max_iter': [100, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 18.8min\n",
      "[Parallel(n_jobs=4)]: Done 1242 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=4)]: Done 1792 tasks      | elapsed: 44.6min\n",
      "[Parallel(n_jobs=4)]: Done 2442 tasks      | elapsed: 61.9min\n",
      "[Parallel(n_jobs=4)]: Done 2880 out of 2880 | elapsed: 74.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Set up gridsearch\n",
    "lr_tv_gs = GridSearchCV(lr_tv_pipe, lr_tv_params, n_jobs=4, cv=5, verbose=1)\n",
    "\n",
    "# Fit the gridsearch to the training data\n",
    "lr_tv_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9947781732484282"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was our highest cross-val accuracy score across model hyperparameter combinations?\n",
    "lr_tv_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=500,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1000000000.0, class_weight=None,\n",
       "                                    dual=False, fit_intercept=True,\n",
       "                                    intercept_scaling=1, l1_ratio=None,\n",
       "                                    max_iter=100, multi_class='warn',\n",
       "                                    n_jobs=None, penalty='l2',\n",
       "                                    random_state=None, solver='liblinear',\n",
       "                                    tol=0.0001, verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What model hyperparameters yielded the highest accuracy score?\n",
    "lr_tv_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr__C': 1000000000.0,\n",
       " 'lr__max_iter': 100,\n",
       " 'lr__penalty': 'l2',\n",
       " 'tvec__max_df': 1.0,\n",
       " 'tvec__max_features': 500,\n",
       " 'tvec__min_df': 1,\n",
       " 'tvec__ngram_range': (1, 2),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the parameters?\n",
    "lr_tv_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9948911648628362"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this model perform on the test set?\n",
    "lr_tv_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "svc_cv_pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()), \n",
    "    ('svc', SVC(gamma='scale')) \n",
    "])\n",
    "\n",
    "# Set up pipeline parameters\n",
    "svc_cv_params = {\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "    'cvec__ngram_range': [(1,1), (1,2), (1,3)], \n",
    "    'cvec__max_features': [100, 250, 500],\n",
    "    'svc__C': [1, 2, 3, 5.5, 7, 8.5, 10, 20, 50], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 62.9min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 161.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 332.8min\n",
      "[Parallel(n_jobs=4)]: Done 810 out of 810 | elapsed: 339.4min finished\n"
     ]
    }
   ],
   "source": [
    "# Set up gridsearch\n",
    "svc_cv_gs = GridSearchCV(svc_cv_pipe, svc_cv_params, n_jobs=4, cv=5, verbose=1)\n",
    "\n",
    "# Fit the gridsearch to the training data\n",
    "svc_cv_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9965537557605546"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was our highest cross-val accuracy score across model hyperparameter combinations?\n",
    "svc_cv_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cvec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=500, min_df=1, ngram_range=(1, 2),\n",
       "                                 preprocessor=None, stop_words='english',\n",
       "                                 strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=3, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What model hyperparameters yielded the highest accuracy score?\n",
    "svc_cv_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 500,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'svc__C': 3}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the parameters?\n",
    "svc_cv_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970702888549914"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this model perform on the test set?\n",
    "svc_cv_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline\n",
    "svc_tv_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()), \n",
    "    ('svc', SVC(gamma='scale')) \n",
    "])\n",
    "\n",
    "# Set up pipeline parameters\n",
    "svc_tv_params = {\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)], \n",
    "    'tvec__max_features': [100, 250, 500],\n",
    "    'svc__C': [1, 2, 3, 5.5, 7, 8.5, 10, 20, 50], \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed: 52.0min\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed: 129.4min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 236.8min\n",
      "[Parallel(n_jobs=4)]: Done 810 out of 810 | elapsed: 242.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Set up gridsearch\n",
    "svc_tv_gs = GridSearchCV(svc_tv_pipe, svc_tv_params, n_jobs=4, cv=5, verbose=1)\n",
    "\n",
    "# Fit the gridsearch to the training data\n",
    "svc_tv_gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9970460763661897"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What was our highest cross-val accuracy score across model hyperparameter combinations?\n",
    "svc_tv_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tvec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=500,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('svc',\n",
       "                 SVC(C=7, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What model hyperparameters yielded the highest accuracy score?\n",
    "svc_tv_gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svc__C': 7,\n",
       " 'tvec__max_features': 500,\n",
       " 'tvec__ngram_range': (1, 1),\n",
       " 'tvec__stop_words': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What were the parameters?\n",
    "svc_tv_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973366262318104"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this model perform on the test set?\n",
    "svc_tv_gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3096, 5)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import test data to get project predictions\n",
    "test_df = pd.read_csv('./data/test_data/combined_test_data.csv')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-31 21:34:27+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Reminder: Texas State Law prohibiting texting ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-31 21:03:18+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Brotherhood for the Fallen Charity Event</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2017-08-31 17:16:43+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>FREE #TRINITY EVENT - Artisan Fair Market - Se...</td>\n",
       "      <td>#TRINITY #LaborDayWeekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-08-31 17:13:36+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Our thoughts and prayers are with the Sacramen...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-08-31 17:10:47+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>How can Dallas residents help animals affected...</td>\n",
       "      <td>#HurricaneHarvey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          0         1  \\\n",
       "0           0  2017-08-31 21:34:27+00:00  DallasPD   \n",
       "1           1  2017-08-31 21:03:18+00:00  DallasPD   \n",
       "2           2  2017-08-31 17:16:43+00:00  DallasPD   \n",
       "3           3  2017-08-31 17:13:36+00:00  DallasPD   \n",
       "4           4  2017-08-31 17:10:47+00:00  DallasPD   \n",
       "\n",
       "                                                   2  \\\n",
       "0  Reminder: Texas State Law prohibiting texting ...   \n",
       "1           Brotherhood for the Fallen Charity Event   \n",
       "2  FREE #TRINITY EVENT - Artisan Fair Market - Se...   \n",
       "3  Our thoughts and prayers are with the Sacramen...   \n",
       "4  How can Dallas residents help animals affected...   \n",
       "\n",
       "                           3  \n",
       "0                        NaN  \n",
       "1                        NaN  \n",
       "2  #TRINITY #LaborDayWeekend  \n",
       "3                        NaN  \n",
       "4           #HurricaneHarvey  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the first 5 rows\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-31 21:34:27+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Reminder: Texas State Law prohibiting texting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-31 21:03:18+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Brotherhood for the Fallen Charity Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-31 17:16:43+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>FREE #TRINITY EVENT - Artisan Fair Market - Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-31 17:13:36+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Our thoughts and prayers are with the Sacramen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-31 17:10:47+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>How can Dallas residents help animals affected...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0         1  \\\n",
       "0  2017-08-31 21:34:27+00:00  DallasPD   \n",
       "1  2017-08-31 21:03:18+00:00  DallasPD   \n",
       "2  2017-08-31 17:16:43+00:00  DallasPD   \n",
       "3  2017-08-31 17:13:36+00:00  DallasPD   \n",
       "4  2017-08-31 17:10:47+00:00  DallasPD   \n",
       "\n",
       "                                                   2  \n",
       "0  Reminder: Texas State Law prohibiting texting ...  \n",
       "1           Brotherhood for the Fallen Charity Event  \n",
       "2  FREE #TRINITY EVENT - Artisan Fair Market - Se...  \n",
       "3  Our thoughts and prayers are with the Sacramen...  \n",
       "4  How can Dallas residents help animals affected...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop 'Unnamed: 0' and hashtage ('3') columns\n",
    "test_df.drop(columns=['Unnamed: 0', '3'], inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates&amp;time</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-08-31 21:34:27+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Reminder: Texas State Law prohibiting texting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-08-31 21:03:18+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Brotherhood for the Fallen Charity Event</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-08-31 17:16:43+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>FREE #TRINITY EVENT - Artisan Fair Market - Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-08-31 17:13:36+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>Our thoughts and prayers are with the Sacramen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-08-31 17:10:47+00:00</td>\n",
       "      <td>DallasPD</td>\n",
       "      <td>How can Dallas residents help animals affected...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dates&time      user  \\\n",
       "0  2017-08-31 21:34:27+00:00  DallasPD   \n",
       "1  2017-08-31 21:03:18+00:00  DallasPD   \n",
       "2  2017-08-31 17:16:43+00:00  DallasPD   \n",
       "3  2017-08-31 17:13:36+00:00  DallasPD   \n",
       "4  2017-08-31 17:10:47+00:00  DallasPD   \n",
       "\n",
       "                                               tweet  \n",
       "0  Reminder: Texas State Law prohibiting texting ...  \n",
       "1           Brotherhood for the Fallen Charity Event  \n",
       "2  FREE #TRINITY EVENT - Artisan Fair Market - Se...  \n",
       "3  Our thoughts and prayers are with the Sacramen...  \n",
       "4  How can Dallas residents help animals affected...  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "test_df.rename(columns={'0': 'dates&time', '1': 'user', '2': 'tweet'}, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dates&time    0\n",
       "user          0\n",
       "tweet         9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dates&time    0\n",
       "user          0\n",
       "tweet         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove rows will null values for 'tweet' and verify changes\n",
    "test_df = test_df[test_df['tweet'].notnull()]\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export clean test data\n",
    "test_df.to_csv('./data/test_data/final_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle / Export Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC / TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit svc pipeline with best hyperparameters\n",
    "best_pipe = Pipeline([\n",
    "    ('tvec', TfidfVectorizer(max_features=500)),\n",
    "    ('svc', SVC(gamma='scale', C=7))\n",
    "])\n",
    "best_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9999273625335948\n",
      "Train cross val score: 0.9970460777980892\n",
      "Test score: 0.9973366262318104\n"
     ]
    }
   ],
   "source": [
    "# Get the score on train and test data\n",
    "print(f'Train score: {best_pipe.score(X_train, y_train)}')\n",
    "print(f'Train cross val score: {cross_val_score(best_pipe, X_train, y_train, cv=5).mean()}')\n",
    "print(f'Test score: {best_pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions on test set of train data\n",
    "y_pred = best_pipe.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X and y for test data\n",
    "test_X = test_df['tweet']\n",
    "\n",
    "# Get predicitons on our true test data\n",
    "test_y_pred = best_pipe.predict(test_X)\n",
    "test_y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filename and export\n",
    "filename = './assets/svc_tv.sav'\n",
    "pickle.dump(best_pipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on our true test data using the pickled model\n",
    "model = pickle.load(open('svc_tv.sav','rb'))\n",
    "print(model.predict(test_X)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression / CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and fit svc pipeline with best hyperparameters\n",
    "best_pipe_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer(max_features=500, ngram_range=(1,2))),\n",
    "    ('lr', LogisticRegression(solver='liblinear', penalty='l1'))\n",
    "])\n",
    "best_pipe_lr.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9979822925998564\n",
      "Train cross val score: 0.9971267854427384\n",
      "Test score: 0.9972882012542069\n"
     ]
    }
   ],
   "source": [
    "# Get the score on train and test data\n",
    "print(f'Train score: {best_pipe_lr.score(X_train, y_train)}')\n",
    "print(f'Train cross val score: {cross_val_score(best_pipe_lr, X_train, y_train, cv=5).mean()}')\n",
    "print(f'Test score: {best_pipe_lr.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions on test set of train data\n",
    "y_pred_lr = best_pipe_lr.predict(X_test)\n",
    "y_pred_lr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X and y for test data\n",
    "test_X = test_df['tweet']\n",
    "\n",
    "# Get predicitons on our true test data\n",
    "test_y_pred_lr = best_pipe_lr.predict(test_X)\n",
    "test_y_pred_lr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set filename and export\n",
    "filename = './assets/lr_cv.sav'\n",
    "pickle.dump(best_pipe_lr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions on our true test data using the pickled model\n",
    "model_lr = pickle.load(open('./assets/lr_cv.sav','rb'))\n",
    "print(model_lr.predict(test_X)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Test Data Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (0, 0), (0, 0), (0, 0), (0, 0)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_comparison = list(zip(model.predict(test_X), model_lr.predict(test_X)))\n",
    "pred_comparison[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets are labelled differently between the two models?\n",
    "count = 0\n",
    "for tup in pred_comparison:\n",
    "    svc, lr = tup\n",
    "    if svc != lr:\n",
    "        count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets between the two models were labelled useful?\n",
    "count = 0\n",
    "for tup in pred_comparison:\n",
    "    svc, lr = tup\n",
    "    if svc == 1 or lr == 1:\n",
    "        count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many tweets were labelled useful in both models?\n",
    "count = 0\n",
    "for tup in pred_comparison:\n",
    "    svc, lr = tup\n",
    "    if svc == 1 and lr == 1:\n",
    "        count +=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
