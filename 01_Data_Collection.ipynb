{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 5: Optimizing Evacuation Routes using Real-Time Traffic Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Song May, Michael Daugherty, Kelly Slatery | US-DSI-10 | 02.21.2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import GetOldTweets3 as got\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credits (using GetOldTweets3 package): Martin Beck, 01.12.2020\n",
    "# https://towardsdatascience.com/how-to-scrape-tweets-from-twitter-59287e20f0f1\n",
    "\n",
    "# Set up variables for first Twitter pull\n",
    "username = 'TxDOT'\n",
    "since_date = '2016-01-01'\n",
    "until_date = '2020-02-10'\n",
    "max_tweets = 18000\n",
    "\n",
    "# Create first query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "# Greate first list of all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# Create filtered list of tweet data\n",
    "user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "# Transform list into the base tweet collection dataframe\n",
    "all_tweets = pd.DataFrame(user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-02-07 22:20:09+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>When you drink and drive in Texas, our officer...</td>\n",
       "      <td>#PlanWhileYouCan #EndTheStreakTX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-02-07 18:05:12+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Want to help traffic instead of sitting in it?...</td>\n",
       "      <td>#TxDOTCareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-02-07 01:10:04+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Are you skilled in automotive work? We'd love ...</td>\n",
       "      <td>#TxDOTCareers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-02-07 00:15:25+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>From a shout to a whisper, we can’t emphasize ...</td>\n",
       "      <td>#EndTheStreakTX #ClickItOrTicket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-02-06 22:14:22+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>We love seeing all the nice things y’all have ...</td>\n",
       "      <td>#txwx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0      1  \\\n",
       "0 2020-02-07 22:20:09+00:00  TxDOT   \n",
       "1 2020-02-07 18:05:12+00:00  TxDOT   \n",
       "2 2020-02-07 01:10:04+00:00  TxDOT   \n",
       "3 2020-02-07 00:15:25+00:00  TxDOT   \n",
       "4 2020-02-06 22:14:22+00:00  TxDOT   \n",
       "\n",
       "                                                   2  \\\n",
       "0  When you drink and drive in Texas, our officer...   \n",
       "1  Want to help traffic instead of sitting in it?...   \n",
       "2  Are you skilled in automotive work? We'd love ...   \n",
       "3  From a shout to a whisper, we can’t emphasize ...   \n",
       "4  We love seeing all the nice things y’all have ...   \n",
       "\n",
       "                                  3  \n",
       "0  #PlanWhileYouCan #EndTheStreakTX  \n",
       "1                     #TxDOTCareers  \n",
       "2                     #TxDOTCareers  \n",
       "3  #EndTheStreakTX #ClickItOrTicket  \n",
       "4                             #txwx  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first 5 tweets from 'TxDOT'\n",
    "pd.DataFrame(user_tweets).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>2016-01-04 00:08:24+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>I-35 Alert: 10 vehicle crash closed down all m...</td>\n",
       "      <td>#my35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>2016-01-01 16:20:21+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Make a #resolution to start 2016 right. #PlanW...</td>\n",
       "      <td>#resolution #PlanWhileYouCan #FindASoberRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>2016-01-01 13:30:35+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>TxDOT offices will be closed today, Jan. 1 in ...</td>\n",
       "      <td>#NewYear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4083</th>\n",
       "      <td>2016-01-01 05:55:08+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>#HappyNewYear from #TxDOT! We hope everyone ha...</td>\n",
       "      <td>#HappyNewYear #TxDOT #NYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>2016-01-01 00:10:13+00:00</td>\n",
       "      <td>TxDOT</td>\n",
       "      <td>Don't start the #NewYear w/ a DWI. #PlanWhileY...</td>\n",
       "      <td>#NewYear #PlanWhileYouCan #FindASoberRide #Hap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0      1  \\\n",
       "4080 2016-01-04 00:08:24+00:00  TxDOT   \n",
       "4081 2016-01-01 16:20:21+00:00  TxDOT   \n",
       "4082 2016-01-01 13:30:35+00:00  TxDOT   \n",
       "4083 2016-01-01 05:55:08+00:00  TxDOT   \n",
       "4084 2016-01-01 00:10:13+00:00  TxDOT   \n",
       "\n",
       "                                                      2  \\\n",
       "4080  I-35 Alert: 10 vehicle crash closed down all m...   \n",
       "4081  Make a #resolution to start 2016 right. #PlanW...   \n",
       "4082  TxDOT offices will be closed today, Jan. 1 in ...   \n",
       "4083  #HappyNewYear from #TxDOT! We hope everyone ha...   \n",
       "4084  Don't start the #NewYear w/ a DWI. #PlanWhileY...   \n",
       "\n",
       "                                                      3  \n",
       "4080                                              #my35  \n",
       "4081       #resolution #PlanWhileYouCan #FindASoberRide  \n",
       "4082                                           #NewYear  \n",
       "4083                          #HappyNewYear #TxDOT #NYE  \n",
       "4084  #NewYear #PlanWhileYouCan #FindASoberRide #Hap...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at last 5 tweets from 'TxDOT'\n",
    "pd.DataFrame(user_tweets).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of Twitter usernames to scrape, exclusing first Twitter user ('TxDOT')\n",
    "# From: https://www.txdot.gov/driver/weather/txdot-twitter-feeds.html\n",
    "twitter_users = ['TxDOTAbilene', 'TxDOTAmarillo', 'TxDOTAtlanta', 'TxDOTAustin', \n",
    "                 'TxDOTBeaumont', 'TxDOTBWD', 'TxDOTBryan', 'TxDOTChildress', 'TxDOT_CRP', \n",
    "                 'TxDOTDallas', 'TxDOTELP', 'TxDOTFortWorth', 'GalvestonFerry', 'TxDOTHouston', \n",
    "                 'HoustonTranstar', 'I35Travel', 'TxDOTLaredo', 'TxDOTLubbock', 'TxDOTLufkin', \n",
    "                 'TxDOTOdessa', 'TxDOTParis', 'TxDOTPharr', 'PortA_Ferry', 'TxDOTSanAngelo', \n",
    "                 'TxDOTSanAntonio', 'TexasHighways', 'TxDOTTyler', 'TxDOTWacoPIO', 'TXDOTWF', \n",
    "                 'TxDOTYoakum', 'ImproveMopac', 'ManorExpressway', 'DFWConnector', 'DriveMidtown', \n",
    "                 'Drive360South', 'LBJexpress', 'NTExpress', 'my290Houston']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twitter_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull remaining users' tweets from the same time period\n",
    "def update_tweets(base_df, user):\n",
    "    \n",
    "    # Set up variables for first Twitter pull\n",
    "    username = user\n",
    "    since_date = '2016-01-01'\n",
    "    until_date = '2020-02-10'\n",
    "    max_tweets = 18000\n",
    "\n",
    "    # Create first query object\n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "    # Greate first list of all tweets\n",
    "    tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "    # Create filtered list of tweet data\n",
    "    user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "    # Transform list into the base tweet collection dataframe\n",
    "    tweets_df = pd.DataFrame(user_tweets)\n",
    "    \n",
    "    # Concatenate new tweets with old tweets\n",
    "    updated = pd.concat([base_df, tweets_df], axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    # Export the new dataframe individually\n",
    "    tweets_df.to_csv(f'./data/data_by_user/{user}_tweets', index=False)\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Done scraping. We added {len(user_tweets)} new tweets. Current df shape: {updated.shape}')\n",
    "    \n",
    "    # Return updated dataframe of all tweets\n",
    "    return updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter #1 now scraping...\n",
      "Done scraping. We added 1196 new tweets. Current df shape: (5281, 4)\n",
      "\n",
      "Time elapsed: 30.133867025375366\n",
      "Twitter #2 now scraping...\n",
      "Done scraping. We added 1757 new tweets. Current df shape: (7038, 4)\n",
      "\n",
      "Time elapsed: 46.58091187477112\n",
      "Twitter #3 now scraping...\n",
      "Done scraping. We added 356 new tweets. Current df shape: (7394, 4)\n",
      "\n",
      "Time elapsed: 10.286750793457031\n",
      "Twitter #4 now scraping...\n",
      "Done scraping. We added 5420 new tweets. Current df shape: (12814, 4)\n",
      "\n",
      "Time elapsed: 144.51120901107788\n",
      "Twitter #5 now scraping...\n",
      "Done scraping. We added 2231 new tweets. Current df shape: (15045, 4)\n",
      "\n",
      "Time elapsed: 52.47301006317139\n",
      "Twitter #6 now scraping...\n",
      "Done scraping. We added 586 new tweets. Current df shape: (15631, 4)\n",
      "\n",
      "Time elapsed: 16.99058508872986\n",
      "Twitter #7 now scraping...\n",
      "Done scraping. We added 762 new tweets. Current df shape: (16393, 4)\n",
      "\n",
      "Time elapsed: 19.221446752548218\n",
      "Twitter #8 now scraping...\n",
      "Done scraping. We added 1761 new tweets. Current df shape: (18154, 4)\n",
      "\n",
      "Time elapsed: 42.15876889228821\n",
      "Twitter #9 now scraping...\n",
      "Done scraping. We added 790 new tweets. Current df shape: (18944, 4)\n",
      "\n",
      "Time elapsed: 20.954066038131714\n",
      "Twitter #10 now scraping...\n",
      "Done scraping. We added 1169 new tweets. Current df shape: (20113, 4)\n",
      "\n",
      "Time elapsed: 28.77706789970398\n",
      "Twitter #11 now scraping...\n",
      "Done scraping. We added 4411 new tweets. Current df shape: (24524, 4)\n",
      "\n",
      "Time elapsed: 116.68503975868225\n",
      "Twitter #12 now scraping...\n",
      "Done scraping. We added 1655 new tweets. Current df shape: (26179, 4)\n",
      "\n",
      "Time elapsed: 40.9729118347168\n",
      "Twitter #13 now scraping...\n",
      "Done scraping. We added 11860 new tweets. Current df shape: (38039, 4)\n",
      "\n",
      "Time elapsed: 264.7479999065399\n",
      "Twitter #14 now scraping...\n",
      "Done scraping. We added 7040 new tweets. Current df shape: (45079, 4)\n",
      "\n",
      "Time elapsed: 171.63731694221497\n",
      "Twitter #15 now scraping...\n",
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=%20from%3Ahoustontranstar%20since%3A2016-01-01%20until%3A2020-02-10&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kelly/anaconda3/envs/dsi/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3327: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Get tweets from above 38 twitters users and add to the all_tweets dataframe\n",
    "\n",
    "# Set up count\n",
    "i = 0\n",
    "\n",
    "# Loop through all twitter users to scrape and add to the all_tweets dataframe, according to Twitter API limits\n",
    "for user in twitter_users:\n",
    "\n",
    "    # Count twitters as they are scraped and get the initial time\n",
    "    i += 1\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Twitter #{i} now scraping...')\n",
    "    \n",
    "    # Get the tweets and update the dataframe\n",
    "    all_tweets = update_tweets(all_tweets, user)\n",
    "    \n",
    "    # Wait the the remainder of 15 minutes\n",
    "    print(f'Time elapsed: {time.time() - t0}')\n",
    "    time.sleep((15*60) - (time.time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=%20from%3Ai35travel%20since%3A2016-01-01%20until%3A2020-02-10&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set up variables for first Twitter pull of second attempt, skipping 'HoustonTranstar'\n",
    "username = 'I35Travel'\n",
    "since_date = '2016-01-01'\n",
    "until_date = '2020-02-10'\n",
    "max_tweets = 18000\n",
    "\n",
    "# Create first query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setUsername(username).setSince(since_date).setUntil(until_date).setMaxTweets(max_tweets)\n",
    "\n",
    "# Greate first list of all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "# Create filtered list of tweet data\n",
    "user_tweets = [[tweet.date, tweet.username, tweet.text, tweet.hashtags] for tweet in tweets]\n",
    "\n",
    "# Transform list into the base tweet collection dataframe\n",
    "all_tweets2 = pd.DataFrame(user_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first 5 tweets from 'I35Travel'\n",
    "pd.DataFrame(user_tweets).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at last 5 tweets from 'I35Travel'\n",
    "pd.DataFrame(user_tweets).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter #16 now scraping...\n",
      "An error occured during an HTTP request: HTTP Error 429: Too Many Requests\n",
      "Try to open in browser: https://twitter.com/search?q=%20from%3Ai35travel%20since%3A2016-01-01%20until%3A2020-02-10&src=typd\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Continue scraping: Get tweets from remaining 23 twitters users and add to the all_tweets dataframe\n",
    "# Skipping 'HoustonTranstar'\n",
    "\n",
    "# Set up count\n",
    "i = 0\n",
    "\n",
    "# Loop through all remaining twitter users to scrape and add to the all_tweets dataframe, \n",
    "# according to Twitter API limits\n",
    "for user in twitter_users[16:]:\n",
    "\n",
    "    # Count twitters as they are scraped and get the initial time\n",
    "    i += 1\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Print progress update\n",
    "    print(f'Twitter #{i} now scraping...')\n",
    "    \n",
    "    # Get the tweets and update the dataframe\n",
    "    all_tweets2 = update_tweets(all_tweets2, user)\n",
    "    \n",
    "    # Wait the the remainder of 15 minutes\n",
    "    print(f'Done. Time elapsed: {time.time() - t0}')\n",
    "    print()\n",
    "    time.sleep((15*60) - (time.time() - t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first 5 tweets\n",
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at last 5 tweets\n",
    "all_tweets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.to_csv('./data/DOT_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
